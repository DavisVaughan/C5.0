<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Class Probability Calculations • C50</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/united/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">C50</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../articles/C5.0.html">Introduction</a>
</li>
<li>
  <a href="../articles/Class_Probability_Calcs.html">Class Probability Calculations</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Class Probability Calculations</h1>
            
          </div>

    
    
<div class="contents">
<p>This document describes exactly how the model computes class probabilities using the data in the terminal nodes. Here is an example model using the iris data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="op">&gt;</span><span class="st"> </span><span class="kw">library</span>(C50)
<span class="op">&gt;</span><span class="st"> </span>mod &lt;-<span class="st"> </span><span class="kw"><a href="../reference/C5.0.html">C5.0</a></span>(Species <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> iris)
<span class="op">&gt;</span><span class="st"> </span><span class="kw">summary</span>(mod)</code></pre></div>
<pre><code>
Call:
C5.0.formula(formula = Species ~ ., data = iris)


C5.0 [Release 2.07 GPL Edition]     Wed Feb  7 11:43:48 2018
-------------------------------

Class specified by attribute `outcome'

Read 150 cases (5 attributes) from undefined.data

Decision tree:

Petal.Length &lt;= 1.9: setosa (50)
Petal.Length &gt; 1.9:
:...Petal.Width &gt; 1.7: virginica (46/1)
    Petal.Width &lt;= 1.7:
    :...Petal.Length &lt;= 4.9: versicolor (48/1)
        Petal.Length &gt; 4.9: virginica (6/2)


Evaluation on training data (150 cases):

        Decision Tree   
      ----------------  
      Size      Errors  

         4    4( 2.7%)   &lt;&lt;


       (a)   (b)   (c)    &lt;-classified as
      ----  ----  ----
        50                (a): class setosa
              47     3    (b): class versicolor
               1    49    (c): class virginica


    Attribute usage:

    100.00% Petal.Length
     66.67% Petal.Width


Time: 0.0 secs</code></pre>
<p>Suppose that we are predicting the sample in row 130 with a petal length of 5.8 and a petal width of 1.6. From this tree, the terminal node shows <code>virginica (6/2)</code> which means a predicted class of the virginica species with a probability of 4/6 = 0.66667. However, we get a different predicted probability:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="op">&gt;</span><span class="st"> </span><span class="kw">predict</span>(mod, iris[<span class="dv">130</span>,], <span class="dt">type =</span> <span class="st">"prob"</span>)</code></pre></div>
<pre><code>        setosa versicolor virginica
130 0.04761905  0.3333333 0.6190476</code></pre>
<p>When we wanted to describe the technical aspects of the <a href="https://www.rulequest.com/see5-info.html">C5.0</a> and <a href="https://www.rulequest.com/cubist-info.html">cubist</a> models, the main source of information on these models was the raw C source code from the <a href="https://www.rulequest.com/download.html">RuleQuest website</a>. For many years, both of these models were proprietary commercial products and we only recently open-sourced. Our intuition is that Quinlan quietly evolved these models from the versions described in the most recent publications to what they are today. For example, it would not be unreasonable to assume that C5.0 uses <a href="https://en.wikipedia.org/wiki/AdaBoost">AdaBoost</a>. From the sources, a similar reweighting scheme is used but it does not appear to be the same.</p>
<p>For classifying new samples, the C sources have</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c">ClassNo PredictTreeClassify(DataRec Case, Tree DecisionTree){
  ClassNo   c, C;
  <span class="dt">double</span>    Prior;
  
  <span class="co">/*  Save total leaf count in ClassSum[0]  */</span>
  ForEach(c, <span class="dv">0</span>, MaxClass) {
    ClassSum[c] = <span class="dv">0</span>;
  }
  
  PredictFindLeaf(Case, DecisionTree, Nil, <span class="fl">1.0</span>);
  
  C = SelectClassGen(DecisionTree-&gt;Leaf, (Boolean)(MCost != Nil), ClassSum);
  
  <span class="co">/*  Set all confidence values in ClassSum  */</span>
  ForEach(c, <span class="dv">1</span>, MaxClass){
    Prior = DecisionTree-&gt;ClassDist[c] / DecisionTree-&gt;Cases;
    ClassSum[c] = (ClassSum[<span class="dv">0</span>] * ClassSum[c] + Prior) / (ClassSum[<span class="dv">0</span>] + <span class="dv">1</span>);
  }
  Confidence = ClassSum[C];
  
  <span class="cf">return</span> C;
}</code></pre></div>
<p>Here:</p>
<ul>
<li>The predicted probability is the “confidence” value</li>
<li>The prior is the class probabilities from the training set. For the iris data, this value is 1/3 for each of the classes</li>
<li>The array <code>ClassSum</code> is the probabilities of each class in the terminal node although <code>ClassSum[0]</code> is the number of samples in the terminal node (which, if there are missing values, can be fractional).</li>
</ul>
<p>For sample 130, the virginica values are:</p>
<pre><code>  (ClassSum[0] * ClassSum[c] + Prior) / (ClassSum[0] + 1)
= (          6 *       (4/6) + (1/3)) / (          6 + 1) 
= 0.6190476</code></pre>
<p>Why is it doing this? This will tend to avoid class predictions that are absolute zero or one.</p>
<p>Basically, it can be viewed to be <em>similar</em> to how Bayesian methods operate where the simple probability estimates are “shrunken” towards the prior probabilities. Note that, as the number of samples in the terminal nodes (<code>ClassSum[0]</code>) becomes large, this operation has less effect on the final results. Suppose <code>ClassSum[0] = 10000</code>, then the predicted virginica probability would be 0.6663337, which is closer to the simple estimate.</p>
<p>This is very much related to the <a href="https://en.wikipedia.org/wiki/Additive_smoothing">Laplace Correction</a>. Traditionally, we would add a value of one to the denominator of the simple estimate and add the number of classes to the bottom, resulting in <code>(4+1)/(6+3) = 0.5555556</code>. C5.0 is substituting the prior probabilities and their sum (always one) into this equation instead.</p>
<p>To be fair, there are well known Bayesian estimates of the sample proportions under different prior distributions for the two class case. For example, if there were two classes, the estimate of the class probability under a uniform prior would be the same as the basic Laplace correction (using the integers and not the fractions). A more flexible Bayesian approach is the <a href="https://en.wikipedia.org/wiki/Beta-binomial_distribution">Beta-Binomial model</a>, which uses a Beta prior instead of the uniform. The downside here is that two extra parameters need to be estimated (and it only is defined for two classes)</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Max Kuhn, Quinlan Ross.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
